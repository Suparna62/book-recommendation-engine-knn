# Step 1: Import Required Libraries
import pandas as pd
from sklearn.neighbors import NearestNeighbors
from scipy.sparse import csr_matrix

# Step 2: Load the datasets
books = pd.read_csv('https://raw.githubusercontent.com/freeCodeCamp/boilerplate-book-recommendation-engine/master/books.csv')
users = pd.read_csv('https://raw.githubusercontent.com/freeCodeCamp/boilerplate-book-recommendation-engine/master/users.csv')
ratings = pd.read_csv('https://raw.githubusercontent.com/freeCodeCamp/boilerplate-book-recommendation-engine/master/ratings.csv')

# Step 3: Filter out users with <200 ratings
user_counts = ratings['user_id'].value_counts()
valid_users = user_counts[user_counts >= 200].index
ratings = ratings[ratings['user_id'].isin(valid_users)]

# Step 4: Filter out books with <100 ratings
book_counts = ratings['book_id'].value_counts()
valid_books = book_counts[book_counts >= 100].index
ratings = ratings[ratings['book_id'].isin(valid_books)]

# Step 5: Merge ratings with book titles
ratings = pd.merge(ratings, books[['book_id', 'book_title']], on='book_id')

# Step 6: Create a pivot table of books Ã— users
book_user_matrix = ratings.pivot_table(index='book_title', columns='user_id', values='book_rating').fillna(0)

# Step 7: Convert to a sparse matrix
book_user_sparse = csr_matrix(book_user_matrix.values)

# Step 8: Fit a KNN model
model = NearestNeighbors(metric='cosine', algorithm='brute')
model.fit(book_user_sparse)

# Step 9: Define the recommendation function
def get_recommends(book_title):
    index = book_user_matrix.index.get_loc(book_title)
    distances, indices = model.kneighbors(book_user_matrix.iloc[index, :].values.reshape(1, -1), n_neighbors=6)

    recs = []
    for i in range(1, len(distances[0])):
        recs.append([book_user_matrix.index[indices[0][i]], distances[0][i]])

    return [book_title, recs]

# Step 10: Test the recommender
recommendations = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
print(recommendations)
